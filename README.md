# Quickstart: Building Data Engineering Pipelines with Snowpark Python

## Overview

Assignment 4 Part A
Replicating Data Engineering Pipelines with Snowpark Python 

## Prerequisites

- Proficiency in Python
- Understanding of the DataFrame API
- Knowledge of Snowflake
- Experience with Git and GitHub

## What You'll Learn

Throughout this Quickstart, you'll gain insights into various Snowflake features, such as:

- Snowflake's Table Format
- Data ingestion with COPY and schema inference
- Data sharing and marketplace strategies
- Change Data Capture (CDC) with Streams
- Creation of Python UDFs and Stored Procedures
- Snowpark DataFrame API and Python programmability
- Warehouse elasticity and dynamic scaling
- Tools such as Visual Studio Code Snowflake extension and SnowCLI
- Task orchestration and observability
- CI/CD pipeline integration using GitHub Actions

## What You'll Need

Before starting, ensure you have:

- A Snowflake account with ACCOUNTADMIN permissions
- Accepted the Anaconda Terms & Conditions for third-party packages
- A GitHub account

## What You'll Build

By the end of this Quickstart, you will have:

- Loaded Parquet data into Snowflake using schema inference
- Set up Snowflake Marketplace data access
- Created a Python UDF for temperature conversion
- Developed a data engineering pipeline with Python stored procedures for incremental data processing
- Orchestrated and monitored pipelines with Snowflake tasks and Snowsight
- Deployed Snowpark Python stored procedures through a CI/CD pipeline

## Conclusion

This Quickstart has equipped you with the knowledge to build a sophisticated data engineering pipeline using Snowpark Python. While we've covered substantial ground, including various Snowflake features and developer tools, there's much more to explore. With these foundational skills, you're now ready to create your own data engineering solutions with Snowpark Python.

## What We've Covered

We've highlighted key aspects of Snowflake, including:

- Snowflake's Table Format and Data ingestion
- Schema inference and data sharing
- CDC with Streams and Python UDFs
- Snowpark DataFrame API and its programmability
- Task orchestration, observability, and GitHub Actions integration

## Related Resources

To further your learning, here are some additional resources:

- [Full Guide on Snowflake Demo](https://quickstarts.snowflake.com/guide/data_engineering_pipelines_with_snowpark_python/#0)
- [Source Code on GitHub](https://github.com/Snowflake-Labs/sfguide-data-engineering-with-snowpark-python)
- [Snowpark Developer Guide for Python](https://docs.snowflake.com/en/developer-guide/snowpark/python/index)


## Related Tools

Enhance your workflow with these tools:

- [Snowflake Visual Studio Code Extension](#)
- [SnowCLI Tool](#)

